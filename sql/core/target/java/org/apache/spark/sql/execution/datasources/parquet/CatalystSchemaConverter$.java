package org.apache.spark.sql.execution.datasources.parquet;
// no position
  class CatalystSchemaConverter$ {
  /**
   * Static reference to the singleton instance of this Scala object.
   */
  public static final CatalystSchemaConverter$ MODULE$ = null;
  public   CatalystSchemaConverter$ () { throw new RuntimeException(); }
  public  void checkFieldName (java.lang.String name) { throw new RuntimeException(); }
  public  org.apache.spark.sql.types.StructType checkFieldNames (org.apache.spark.sql.types.StructType schema) { throw new RuntimeException(); }
  public  void analysisRequire (scala.Function0<java.lang.Object> f, java.lang.String message) { throw new RuntimeException(); }
  private  int computeMinBytesForPrecision (int precision) { throw new RuntimeException(); }
  private  int[] MIN_BYTES_FOR_PRECISION () { throw new RuntimeException(); }
  public  int minBytesForPrecision (int precision) { throw new RuntimeException(); }
  public  int MAX_PRECISION_FOR_INT32 () { throw new RuntimeException(); }
  public  int MAX_PRECISION_FOR_INT64 () { throw new RuntimeException(); }
  public  int maxPrecisionForBytes (int numBytes) { throw new RuntimeException(); }
}
